{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook implements all the experimentats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "# Automatically re-import files when updated\n",
    "%load_ext autoreload\n",
    "%autoreload 2  \n",
    "# Load packages\n",
    "from models import Inception, downsampler, upsampler\n",
    "from utils import *\n",
    "from train import run\n",
    "from evaluate import evaluate\n",
    "from matplotlib import pyplot as plt\n",
    "import time, json, pandas as pd, IPython\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to be tested\n",
    "params = {\n",
    "    \"adv_attack\":[fgsm, ifgsm, carlini_wagner],\n",
    "    \"epsilon\":[tf.constant(0.01), tf.constant(0.1)],\n",
    "    \"datasets\":[tf.keras.datasets.mnist.load_data(), tf.keras.datasets.fashion_mnist.load_data(), tf.keras.datasets.cifar10.load_data()]\n",
    "}\n",
    "params = product(*params.values())\n",
    "\n",
    "# Loop over parameters\n",
    "results = {}\n",
    "for i, (adv_attack, epsilon, ((X_train, y_train), (X_test, y_test))) in enumerate(params):\n",
    "    # Convert data to tf dataset \n",
    "    data_train = dataset_from_arrays(X_train, y_train)\n",
    "    data_test = dataset_from_arrays(X_test, y_test)\n",
    "\n",
    "    # Train the models and save them\n",
    "    run(data_train, adv_attack, epsilon)\n",
    "\n",
    "    # Load models\n",
    "    with tf.keras.utils.custom_object_scope({\n",
    "        'Inception': Inception,\n",
    "        \"downsampler\": downsampler,\n",
    "        \"upsampler\": upsampler\n",
    "        }):\n",
    "        decoder = tf.keras.models.load_model(\"decoder.keras\")\n",
    "        encoder = tf.keras.models.load_model(\"encoder.keras\")\n",
    "        classifier = tf.keras.models.load_model(\"classifier.keras\")\n",
    "\n",
    "    # Evaluate and save\n",
    "    accuracies = evaluate(data_test, X_train/BATCH_SIZE, encoder, decoder, classifier, adv_attack)\n",
    "    results[i] = accuracies\n",
    "    json.dump(results, open(\"results.json\", mode=\"w\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
